{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Lane Detection Using UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "a0cf3c5d-d69f-41dd-bd02-dd59b05ee4b2",
    "_uuid": "c33b670a-b8fa-4d63-ba76-6e529a57b3a5",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9.54106,
     "end_time": "2023-11-15T17:36:34.174733",
     "exception": false,
     "start_time": "2023-11-15T17:36:24.633673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import required libraries/dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.013674,
     "end_time": "2023-11-15T17:36:34.194777",
     "exception": false,
     "start_time": "2023-11-15T17:36:34.181103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train path\n",
    "train_path = 'tusimple_preprocessed/training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 4.346923,
     "end_time": "2023-11-15T17:36:38.54838",
     "exception": false,
     "start_time": "2023-11-15T17:36:34.201457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7252 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a generator and get the images from the directory\n",
    "img_generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "seed = 10\n",
    "images_set = img_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    shuffle=False,\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    target_size=(256, 320)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 80.864283,
     "end_time": "2023-11-15T17:37:59.418981",
     "exception": false,
     "start_time": "2023-11-15T17:36:38.554698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Batch 10\n",
      "Batch 20\n",
      "Batch 30\n",
      "Batch 40\n",
      "Batch 50\n",
      "Batch 60\n",
      "Batch 70\n",
      "Batch 80\n",
      "Batch 90\n",
      "Batch 100\n",
      "Batch 110\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Assign the images in 'images_set' to two seperate arrays:\n",
    "assign the road images to 'X' and the ground truth masks to 'Y'\n",
    "'''\n",
    "num_images = 7252 # gotten from the output of the cell above\n",
    "num_batches = num_images // 64 + 1\n",
    "\n",
    "# initialize an empty list to store the images\n",
    "X = []\n",
    "Y = []\n",
    "# loop over the batches and extract the images\n",
    "for i in range(num_batches):\n",
    "    batch = next(images_set)\n",
    "    batch_images = batch[0] # this contains the images\n",
    "    batch_labels = batch[1] # this contains 0s and 1s\n",
    "    for ind, lb in enumerate(batch_labels):\n",
    "        '''\n",
    "        a label of 0 means the image belongs to ground truth image,\n",
    "        and a label of 1 means that the image belongs to the ground truth mask\n",
    "        '''\n",
    "        if lb == 0: \n",
    "            X.append(batch_images[ind])\n",
    "        else:\n",
    "            Y.append(np.mean(batch_images[ind], axis=2)) # Y shape is (m, 256, 320)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Batch {i}')\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.055066,
     "end_time": "2023-11-15T17:38:01.480982",
     "exception": false,
     "start_time": "2023-11-15T17:37:59.425916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, Y = shuffle(X, Y, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.721103,
     "end_time": "2023-11-15T17:38:02.209736",
     "exception": false,
     "start_time": "2023-11-15T17:38:01.488633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize and reshape the mask set (Y)\n",
    "Y = (Y >= 100).astype('int').reshape(-1, 256, 320, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.402873,
     "end_time": "2023-11-15T17:38:02.619387",
     "exception": false,
     "start_time": "2023-11-15T17:38:02.216514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y.min(), Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.12933,
     "end_time": "2023-11-15T17:38:03.755655",
     "exception": false,
     "start_time": "2023-11-15T17:38:02.626325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we get 2000 images for training and evaluation\n",
    "X = np.array(X[:2000])\n",
    "Y = np.array(Y[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.062692,
     "end_time": "2023-11-15T17:38:04.825418",
     "exception": false,
     "start_time": "2023-11-15T17:38:03.762726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the datset into train and val sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=.1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.014906,
     "end_time": "2023-11-15T17:38:04.84749",
     "exception": false,
     "start_time": "2023-11-15T17:38:04.832584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_val:\", Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.229424,
     "end_time": "2023-11-15T17:38:05.083587",
     "exception": false,
     "start_time": "2023-11-15T17:38:04.854163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# free the RAM from undesired clutters\n",
    "import gc\n",
    "del X, Y, images_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.825002,
     "end_time": "2023-11-15T17:38:09.915625",
     "exception": false,
     "start_time": "2023-11-15T17:38:05.090623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the model's architecture\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "def unet(input_size=(256,320,3)):\n",
    "    inputs = Input(input_size)\n",
    "    rescale = keras.layers.Rescaling(1./255)(inputs)\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(rescale)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    # Decoder\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(drop5))\n",
    "    merge6 = Concatenate(axis=3)([conv4, up6])\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
    "    merge7 = Concatenate(axis=3)([conv3, up7])\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv7))\n",
    "    merge8 = Concatenate(axis=3)([conv2, up8])\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv8))\n",
    "    merge9 = Concatenate(axis=3)([conv1, up9])\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.164741,
     "end_time": "2023-11-15T17:38:10.088118",
     "exception": false,
     "start_time": "2023-11-15T17:38:09.923377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=keras.losses.BinaryFocalCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5952.850832,
     "end_time": "2023-11-15T19:17:22.953521",
     "exception": false,
     "start_time": "2023-11-15T17:38:10.102689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Define the path to the folder where you want to save TensorBoard logs\n",
    "tensorboard_log_dir = '/kaggle/working/logs'\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir=tensorboard_log_dir, histogram_freq=1)\n",
    "\n",
    "# train the model\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "\n",
    "# Add TensorBoard callback to the list of callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "    tensorboard_callback,\n",
    "]\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_val)\n",
    "preds.max(), preds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results from the val set.\n",
    "plt.figure(figsize=(10, 45))\n",
    "s, e = 90, 98\n",
    "index = 1\n",
    "\n",
    "preds = (preds >= .5).astype('int')\n",
    "for i, j, k in zip(X_val[s:e], preds[s:e], Y_val[s:e]):\n",
    "    # write these images into file as well\n",
    "    cv2.imwrite(f'./out/img-{index}.jpg', i)\n",
    "    cv2.imwrite(f'./out/pred-{index}.jpg', j*255.)\n",
    "    cv2.imwrite(f'./out/ground-{index}.jpg', k*255.)\n",
    "    \n",
    "    plt.subplot(10, 2, index)\n",
    "    plt.imshow(i/255.)\n",
    "    plt.title('Ground truth image')\n",
    "    \n",
    "    plt.subplot(10, 2, index+1)\n",
    "    plt.imshow(j, cmap='gray')\n",
    "    plt.title('Pred mask')\n",
    "    index += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metrices\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recal = tf.keras.metrics.Recall()\n",
    "iou = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])\n",
    "\n",
    "\n",
    "# accuracy\n",
    "accuracy.update_state(Y_val, preds)\n",
    "accuracy_value = accuracy.result().numpy()\n",
    "# precision\n",
    "precision.update_state(Y_val, preds)\n",
    "precision_value = precision.result().numpy()\n",
    "# recal\n",
    "recal.update_state(Y_val, preds)\n",
    "recal_value = recal.result().numpy()\n",
    "# f1 score\n",
    "f1_score = 2 / ((1 / precision_value) + (1 / recal_value))\n",
    "\n",
    "# Intersection over union (IoU)\n",
    "iou.update_state(Y_val, preds)\n",
    "iou_value = iou.result().numpy()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_value)\n",
    "print(\"Precision:\", precision_value)\n",
    "print(\"Recall:\", recal_value)\n",
    "print('F1 Score: ', f1_score)\n",
    "print('IoU: ', iou_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create metrices\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recal = tf.keras.metrics.Recall()\n",
    "iou = tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "# Calculate MSE\n",
    "mse_value = mean_squared_error(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_value = math.sqrt(mse_value)\n",
    "# accuracy\n",
    "accuracy.update_state(Y_val, preds)\n",
    "accuracy_value = accuracy.result().numpy()\n",
    "# precision\n",
    "precision.update_state(Y_val, preds)\n",
    "precision_value = precision.result().numpy()\n",
    "# recal\n",
    "recal.update_state(Y_val, preds)\n",
    "recal_value = recal.result().numpy()\n",
    "# f1 score\n",
    "f1_score = 2 / ((1 / precision_value) + (1 / recal_value))\n",
    "\n",
    "# Intersection over union (IoU)\n",
    "iou.update_state(Y_val, preds)\n",
    "iou_value = iou.result().numpy()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_value)\n",
    "print(\"Precision:\", precision_value)\n",
    "print(\"Recall:\", recal_value)\n",
    "print('F1 Score: ', f1_score)\n",
    "print('IoU: ', iou_value)\n",
    "# Print the results\n",
    "print(\"Mean Squared Error (MSE):\", mse_value)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPHICAL VISUALIZATION OF METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.186333,
     "end_time": "2023-11-15T19:17:24.715644",
     "exception": false,
     "start_time": "2023-11-15T19:17:23.529311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training and validation metrics with markers for starting and ending points\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(2, 1, 1)  # Two subplots in a vertical arrangement\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for loss with padding\n",
    "\n",
    "# Display values for starting and ending points on the loss plot\n",
    "start_loss_coord = (0, history.history['loss'][0])\n",
    "end_loss_coord = (epochs-1, history.history['loss'][-1])\n",
    "plt.text(*start_loss_coord, f'({start_loss_coord[0]}, {start_loss_coord[1]:.4f})', color='green', fontsize=10, ha='right', weight='bold')\n",
    "plt.text(*end_loss_coord, f'({end_loss_coord[0]}, {end_loss_coord[1]:.4f})', color='red', fontsize=10, ha='right', weight='bold')\n",
    "\n",
    "plt.subplot(2, 1, 2)  # Second subplot for accuracy\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for accuracy with padding\n",
    "\n",
    "# Display values for starting and ending points on the accuracy plot\n",
    "start_accuracy_coord = (0, history.history['accuracy'][0])\n",
    "end_accuracy_coord = (epochs-1, history.history['accuracy'][-1])\n",
    "plt.text(*start_accuracy_coord, f'({start_accuracy_coord[0]}, {start_accuracy_coord[1]:.4f})', color='green', fontsize=10, ha='right', weight='bold')\n",
    "plt.text(*end_accuracy_coord, f'({end_accuracy_coord[0]}, {end_accuracy_coord[1]:.4f})', color='red', fontsize=10, ha='right', weight='bold')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better visualization\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.494242,
     "end_time": "2023-11-15T19:17:26.875816",
     "exception": false,
     "start_time": "2023-11-15T19:17:25.381574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training and validation metrics with markers for starting and ending points\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(2, 1, 1)  # Two subplots in a vertical arrangement\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for loss with padding\n",
    "\n",
    "# Display values for starting and ending points on the loss plot\n",
    "start_loss_coord = (0, history.history['loss'][0])\n",
    "end_loss_coord = (epochs-1, history.history['loss'][-1])\n",
    "plt.text(*start_loss_coord, f'({start_loss_coord[0]}, {start_loss_coord[1]:.4f})', color='green', fontsize=10, ha='right', weight='bold')\n",
    "plt.text(*end_loss_coord, f'({end_loss_coord[0]}, {end_loss_coord[1]:.4f})', color='red', fontsize=10, ha='right', weight='bold')\n",
    "\n",
    "plt.subplot(2, 1, 2)  # Second subplot for accuracy\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for accuracy with padding\n",
    "\n",
    "# Display values for starting and ending points on the accuracy plot\n",
    "start_accuracy_coord = (0, history.history['accuracy'][0])\n",
    "end_accuracy_coord = (epochs-1, history.history['accuracy'][-1])\n",
    "plt.text(*start_accuracy_coord, f'({start_accuracy_coord[0]}, {start_accuracy_coord[1]:.4f})', color='green', fontsize=10, ha='right', weight='bold')\n",
    "plt.text(*end_accuracy_coord, f'({end_accuracy_coord[0]}, {end_accuracy_coord[1]:.4f})', color='red', fontsize=10, ha='right', weight='bold')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better visualization\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('training_validation_plot.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.12263,
     "end_time": "2023-11-15T19:17:28.5692",
     "exception": false,
     "start_time": "2023-11-15T19:17:27.44657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training and validation metrics with dot markers for starting and ending points\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(2, 1, 1)  # Two subplots in a vertical arrangement\n",
    "\n",
    "# Plot without 'o' marker for all epochs\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='None', linestyle='-', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='None', linestyle='-', color='orange')\n",
    "\n",
    "# Dot marker for starting point\n",
    "plt.scatter(*start_loss_coord, color='green', s=50, label='Start') \n",
    "\n",
    "# Dot marker for ending point\n",
    "plt.scatter(*end_loss_coord, color='red', s=50, label='End')  \n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for loss with padding\n",
    "\n",
    "# Display values for starting and ending points on the loss plot\n",
    "plt.text(*start_loss_coord, f'({start_loss_coord[0]}, {start_loss_coord[1]:.4f})', color='green', fontsize=10, ha='right', va='bottom', weight='bold')\n",
    "plt.text(*end_loss_coord, f'({end_loss_coord[0]}, {end_loss_coord[1]:.4f})', color='red', fontsize=10, ha='right', va='bottom', weight='bold')\n",
    "\n",
    "plt.subplot(2, 1, 2)  # Second subplot for accuracy\n",
    "\n",
    "# Plot without 'o' marker for all epochs\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='None', linestyle='-', color='blue')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='None', linestyle='-', color='orange')\n",
    "\n",
    "# Dot marker for starting point\n",
    "plt.scatter(*start_accuracy_coord, color='green', s=50, label='Start')  \n",
    "\n",
    "# Dot marker for ending point\n",
    "plt.scatter(*end_accuracy_coord, color='red', s=50, label='End')  \n",
    "\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)  # Set y-axis limits for accuracy with padding\n",
    "\n",
    "# Display values for starting and ending points on the accuracy plot\n",
    "plt.text(*start_accuracy_coord, f'({start_accuracy_coord[0]}, {start_accuracy_coord[1]:.4f})', color='green', fontsize=10, ha='right', va='bottom', weight='bold')\n",
    "plt.text(*end_accuracy_coord, f'({end_accuracy_coord[0]}, {end_accuracy_coord[1]:.4f})', color='red', fontsize=10, ha='right', va='bottom', weight='bold')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better visualization\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('training_validation_plot.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECALL CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall\n",
    "recall_val = recall_score(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot Recall Curve\n",
    "plt.plot([0, 1], [0, recall_val], label=f'Recall: {recall_val:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('recall_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRECISION CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calculate precision\n",
    "precision_val = precision_score(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot Precision Curve\n",
    "plt.plot([0, 1], [0, precision_val], label=f'Precision: {precision_val:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('precision_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRECISION RECALL CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Calculate precision-recall curve values\n",
    "precision, recall, _ = precision_recall_curve(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot Recall-Precision Curve\n",
    "plt.plot(recall, precision, label='Recall-Precision Curve', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Recall-Precision Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('recall_precision_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score_val = f1_score(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot F1 Score Curve\n",
    "plt.plot([0, 1], [0, f1_score_val], label=f'F1 Score: {f1_score_val:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('f1_score_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACCURACY CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy Curve\n",
    "plt.plot([0, 1], [0, accuracy_value], label=f'Accuracy: {accuracy_value:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoU CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Calculate True Positive, False Positive, False Negative\n",
    "tp = conf_matrix[1, 1]\n",
    "fp = conf_matrix[0, 1]\n",
    "fn = conf_matrix[1, 0]\n",
    "\n",
    "# Calculate IoU (Jaccard Index)\n",
    "iou_val = tp / (tp + fp + fn)\n",
    "\n",
    "# Plot IoU Curve\n",
    "plt.plot([0, 1], [0, iou_val], label=f'IoU: {iou_val:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('IoU Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('iou_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRECISION-RECALL CURVE(WITH VALUES)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Recall Curve with values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label='Recall Curve', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Recall-Precision Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Annotate Recall and Precision values on the plot\n",
    "for i, txt in enumerate(recall):\n",
    "    plt.annotate(f'Recall: {recall[i]:.3f}\\nPrecision: {precision[i]:.3f}', (recall[i], precision[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "# Show the Recall Curve plot\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall\n",
    "recall_val = recall_score(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Plot Recall Curve\n",
    "plt.plot([0, 1], [0, recall_val], label=f'Recall: {recall_val:.4f}', marker='o')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Annotate starting and ending point values\n",
    "plt.annotate(f'(0, 0)', (0, 0), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "plt.annotate(f'(1, {recall_val:.4f})', (1, recall_val), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.savefig('recall_curve.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming preds and Y_val are numpy arrays\n",
    "\n",
    "# Calculate False Positive Rate (FPR), True Positive Rate (TPR), and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(Y_val.flatten(), preds.flatten())\n",
    "\n",
    "# Calculate Area Under the Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Print AUC value\n",
    "print(\"Area Under the Curve (AUC): {:.2f}\".format(roc_auc))\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3482689,
     "sourceId": 6082912,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4003339,
     "sourceId": 6967907,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6081.263034,
   "end_time": "2023-11-15T19:17:34.511846",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-15T17:36:13.248812",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
